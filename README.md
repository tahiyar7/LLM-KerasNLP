# LLM-KerasNLP

Hi this is Tahiya. This project has used two diffrenet sets of dataset to understand and create insights results to know how much text being generated by AI and the students. I have seen a decent result after F1 Score and consfusion matrix.

Workflow
Install Package
Import Library
Load & Explore: Vizualization
Add new dataset: Visualization
Prepare the data
LLM Model
The F1 score is a measure of a test's accuracy and is especially useful when dealing with imbalanced datasets. An F1 score of 0.91 indicates a high level of accuracy, meaning that the test or model is performing well in terms of both precision and recall. To better understand this, let's break down the meaning of an F1 score and the components of a confusion matrix.

Confusion Matrix Components A confusion matrix for a binary classification problem is structured as follows:

